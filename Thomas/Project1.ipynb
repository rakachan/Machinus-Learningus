{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from proj1_helpers import *\n",
    "from helpers import *\n",
    "from implementations import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Define seed for train/test random splitting\n",
    "seed = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_TRAIN_PATH = 'data/train.csv'\n",
    "DATA_TEST_PATH = 'data/test.csv'\n",
    "OUTPUT_PATH = 'data/output_ridge_regression.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import *\n",
    "from crossvalidation import *\n",
    "\n",
    "from implementations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1, data2, data3, y1, y2, y3 = split_models_and_process(tX, y)\n",
    "test1, test2, test3, id1, id2, id3 = split_models_and_process(tX_test, ids_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99913, 442)\n",
      "(77544, 577)\n",
      "(72543, 962)\n"
     ]
    }
   ],
   "source": [
    "print(data1.shape)\n",
    "print(data2.shape)\n",
    "print(data3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thomas\\workspace\\PROJET_ML\\helpers.py:20: RuntimeWarning: overflow encountered in square\n",
      "  return 1 / 2 * np.mean(e ** 2)\n"
     ]
    }
   ],
   "source": [
    "weights, loss = least_squares_gd(y1, data1, None, 100, 0.01)\n",
    "# Overflows: not good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thomas\\workspace\\PROJET_ML\\helpers.py:20: RuntimeWarning: overflow encountered in square\n",
      "  return 1 / 2 * np.mean(e ** 2)\n"
     ]
    }
   ],
   "source": [
    "weights, loss = least_squares_sgd(y1, data1, None, 100, 0.01)\n",
    "# Also overflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for a jet = 0\n",
      "0 - Training accuracy: 0.831326 / Test accuracy : 0.833750\n",
      "1 - Training accuracy: 0.830970 / Test accuracy : 0.833850\n",
      "2 - Training accuracy: 0.831081 / Test accuracy : 0.832549\n",
      "3 - Training accuracy: 0.831615 / Test accuracy : 0.826844\n",
      "4 - Training accuracy: 0.831804 / Test accuracy : 0.826844\n",
      "5 - Training accuracy: 0.831215 / Test accuracy : 0.832249\n",
      "6 - Training accuracy: 0.831938 / Test accuracy : 0.823441\n",
      "7 - Training accuracy: 0.830547 / Test accuracy : 0.836953\n",
      "8 - Training accuracy: 0.831482 / Test accuracy : 0.827044\n",
      "9 - Training accuracy: 0.830903 / Test accuracy : 0.831949\n",
      "\n",
      "Average test accuracy: 0.830547\n",
      "Variance test accuracy: 0.000016\n",
      "Min test accuracy: 0.823441\n",
      "Max test accuracy: 0.836953\n"
     ]
    }
   ],
   "source": [
    "k_fold = 10\n",
    "\n",
    "# Model parameters\n",
    "lamb = 0.002\n",
    "\n",
    "accs_train = []\n",
    "accs_test = []\n",
    "max_acc = 0\n",
    "w1 = []\n",
    "\n",
    "print(\"Accuracy for a jet = 0\")\n",
    "k_indices = build_k_indices(y1, k_fold, seed)\n",
    "\n",
    "for k in range(k_fold):\n",
    "    acc_train, acc_test, weights = cross_validation(y1, data1, k_indices, k, ridge_regression, lambda_=lamb)\n",
    "    if (acc_test>max_acc):\n",
    "        w1 = weights\n",
    "    accs_train.append(acc_train)\n",
    "    accs_test.append(acc_test)\n",
    "    \n",
    "for i in range(len(accs_train)):\n",
    "    print(\"%d - Training accuracy: %f / Test accuracy : %f\" % (i, accs_train[i], accs_test[i]))\n",
    "\n",
    "print(\"\\nAverage test accuracy: %f\" % np.mean(accs_test))\n",
    "print(\"Variance test accuracy: %f\" % np.var(accs_test))\n",
    "print(\"Min test accuracy: %f\" % np.min(accs_test))\n",
    "print(\"Max test accuracy: %f\" % np.max(accs_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for a jet = 1\n",
      "0 - Training accuracy: 0.770498 / Test accuracy : 0.773278\n",
      "1 - Training accuracy: 0.772404 / Test accuracy : 0.766701\n",
      "2 - Training accuracy: 0.771215 / Test accuracy : 0.770054\n",
      "3 - Training accuracy: 0.771272 / Test accuracy : 0.770054\n",
      "4 - Training accuracy: 0.772347 / Test accuracy : 0.765153\n",
      "5 - Training accuracy: 0.770513 / Test accuracy : 0.776760\n",
      "6 - Training accuracy: 0.772175 / Test accuracy : 0.769925\n",
      "7 - Training accuracy: 0.771874 / Test accuracy : 0.769151\n",
      "8 - Training accuracy: 0.771630 / Test accuracy : 0.767088\n",
      "9 - Training accuracy: 0.772590 / Test accuracy : 0.768507\n",
      "\n",
      "Average test accuracy: 0.769667\n",
      "Variance test accuracy: 0.000010\n",
      "Min test accuracy: 0.765153\n",
      "Max test accuracy: 0.776760\n"
     ]
    }
   ],
   "source": [
    "k_fold = 10\n",
    "\n",
    "# Model parameters\n",
    "lamb = 0.001\n",
    "\n",
    "accs_train = []\n",
    "accs_test = []\n",
    "max_acc = 0\n",
    "w2 = []\n",
    "print(\"Accuracy for a jet = 1\")\n",
    "k_indices = build_k_indices(y2, k_fold, seed)\n",
    "\n",
    "for k in range(k_fold):\n",
    "    acc_train, acc_test, weights = cross_validation(y2, data2, k_indices, k, ridge_regression, lambda_=lamb)\n",
    "    if (acc_test>max_acc):\n",
    "        w2 = weights\n",
    "    accs_train.append(acc_train)\n",
    "    accs_test.append(acc_test)\n",
    "    \n",
    "for i in range(len(accs_train)):\n",
    "    print(\"%d - Training accuracy: %f / Test accuracy : %f\" % (i, accs_train[i], accs_test[i]))\n",
    "\n",
    "print(\"\\nAverage test accuracy: %f\" % np.mean(accs_test))\n",
    "print(\"Variance test accuracy: %f\" % np.var(accs_test))\n",
    "print(\"Min test accuracy: %f\" % np.min(accs_test))\n",
    "print(\"Max test accuracy: %f\" % np.max(accs_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for a jet = 2 or 3\n",
      "0 - Training accuracy: 0.799635 / Test accuracy : 0.798042\n",
      "1 - Training accuracy: 0.799498 / Test accuracy : 0.795561\n",
      "2 - Training accuracy: 0.798808 / Test accuracy : 0.795423\n",
      "3 - Training accuracy: 0.798288 / Test accuracy : 0.798870\n",
      "4 - Training accuracy: 0.799329 / Test accuracy : 0.796250\n",
      "5 - Training accuracy: 0.799023 / Test accuracy : 0.803143\n",
      "6 - Training accuracy: 0.799314 / Test accuracy : 0.793769\n",
      "7 - Training accuracy: 0.799498 / Test accuracy : 0.797353\n",
      "8 - Training accuracy: 0.799544 / Test accuracy : 0.789633\n",
      "9 - Training accuracy: 0.799452 / Test accuracy : 0.789495\n",
      "\n",
      "Average test accuracy: 0.795754\n",
      "Variance test accuracy: 0.000015\n",
      "Min test accuracy: 0.789495\n",
      "Max test accuracy: 0.803143\n"
     ]
    }
   ],
   "source": [
    "k_fold = 10\n",
    "\n",
    "# Model parameters\n",
    "lamb = 0.001\n",
    "\n",
    "accs_train = []\n",
    "accs_test = []\n",
    "max_acc = 0\n",
    "w3 = []\n",
    "\n",
    "print(\"Accuracy for a jet = 2 or 3\")\n",
    "k_indices = build_k_indices(y3, k_fold, seed)\n",
    "\n",
    "for k in range(k_fold):\n",
    "    acc_train, acc_test, weights = cross_validation(y3, data3, k_indices, k, ridge_regression, lambda_=lamb)\n",
    "    if (acc_test>max_acc):\n",
    "        w3 = weights\n",
    "    accs_train.append(acc_train)\n",
    "    accs_test.append(acc_test)\n",
    "    \n",
    "for i in range(len(accs_train)):\n",
    "    print(\"%d - Training accuracy: %f / Test accuracy : %f\" % (i, accs_train[i], accs_test[i]))\n",
    "\n",
    "print(\"\\nAverage test accuracy: %f\" % np.mean(accs_test))\n",
    "print(\"Variance test accuracy: %f\" % np.var(accs_test))\n",
    "print(\"Min test accuracy: %f\" % np.min(accs_test))\n",
    "print(\"Max test accuracy: %f\" % np.max(accs_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(962,)\n"
     ]
    }
   ],
   "source": [
    "print(w1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19,)\n",
      "(19,)\n",
      "(19,)\n",
      "(19,)\n",
      "(19,)\n",
      "(19,)\n",
      "(19,)\n",
      "(19,)\n",
      "(19,)\n",
      "(19,)\n",
      "0 - Training accuracy: 0.600452 / Test accuracy : 0.598539\n",
      "1 - Training accuracy: 0.745171 / Test accuracy : 0.741968\n",
      "2 - Training accuracy: 0.808550 / Test accuracy : 0.809228\n",
      "3 - Training accuracy: 0.382789 / Test accuracy : 0.388049\n",
      "4 - Training accuracy: 0.740422 / Test accuracy : 0.745071\n",
      "5 - Training accuracy: 0.593579 / Test accuracy : 0.593334\n",
      "6 - Training accuracy: 0.762698 / Test accuracy : 0.752177\n",
      "7 - Training accuracy: 0.748485 / Test accuracy : 0.757181\n",
      "8 - Training accuracy: 0.744837 / Test accuracy : 0.744970\n",
      "9 - Training accuracy: 0.745515 / Test accuracy : 0.741968\n",
      "\n",
      "Average test accuracy: 0.687249\n",
      "Variance test accuracy: 0.014286\n",
      "Min test accuracy: 0.388049\n",
      "Max test accuracy: 0.809228\n"
     ]
    }
   ],
   "source": [
    "k_fold = 10\n",
    "\n",
    "# Split data in k-fold\n",
    "k_indices = build_k_indices(y1, k_fold, seed)\n",
    "\n",
    "# Model parameters\n",
    "gamma = 0.01\n",
    "max_iter = 500\n",
    "\n",
    "accs_train = []\n",
    "accs_test = []\n",
    "\n",
    "for k in range(k_fold):\n",
    "    acc_train, acc_test = cross_validation(y1, data1, k_indices, k, logistic_regression, initial_w = None, max_iters=max_iter, gamma=gamma)\n",
    "    accs_train.append(acc_train)\n",
    "    accs_test.append(acc_test)\n",
    "    \n",
    "for i in range(len(accs_train)):\n",
    "    print(\"%d - Training accuracy: %f / Test accuracy : %f\" % (i, accs_train[i], accs_test[i]))\n",
    "\n",
    "print(\"\\nAverage test accuracy: %f\" % np.mean(accs_test))\n",
    "print(\"Variance test accuracy: %f\" % np.var(accs_test))\n",
    "print(\"Min test accuracy: %f\" % np.min(accs_test))\n",
    "print(\"Max test accuracy: %f\" % np.max(accs_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularized Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - Training accuracy: 0.744948 / Test accuracy : 0.743970\n",
      "1 - Training accuracy: 0.768925 / Test accuracy : 0.768091\n",
      "2 - Training accuracy: 0.763354 / Test accuracy : 0.773696\n",
      "3 - Training accuracy: 0.789155 / Test accuracy : 0.784406\n",
      "4 - Training accuracy: 0.745048 / Test accuracy : 0.743069\n",
      "5 - Training accuracy: 0.527586 / Test accuracy : 0.526374\n",
      "6 - Training accuracy: 0.807960 / Test accuracy : 0.803123\n",
      "7 - Training accuracy: 0.642801 / Test accuracy : 0.641077\n",
      "8 - Training accuracy: 0.665899 / Test accuracy : 0.655790\n",
      "9 - Training accuracy: 0.745193 / Test accuracy : 0.741768\n",
      "\n",
      "Average test accuracy: 0.718136\n",
      "Variance test accuracy: 0.006564\n",
      "Min test accuracy: 0.526374\n",
      "Max test accuracy: 0.803123\n"
     ]
    }
   ],
   "source": [
    "k_fold = 10\n",
    "\n",
    "# Split data in k-fold\n",
    "k_indices = build_k_indices(y1, k_fold, seed)\n",
    "\n",
    "# Model parameters\n",
    "gamma = 0.01\n",
    "max_iter = 500\n",
    "lambda_ = 0.1\n",
    "\n",
    "accs_train = []\n",
    "accs_test = []\n",
    "\n",
    "for k in range(k_fold):\n",
    "    acc_train, acc_test = cross_validation(y1, data1, k_indices, k, reg_logistic_regression, lambda_=lambda_, initial_w = None, max_iters=max_iter, gamma=gamma)\n",
    "    accs_train.append(acc_train)\n",
    "    accs_test.append(acc_test)\n",
    "    \n",
    "for i in range(len(accs_train)):\n",
    "    print(\"%d - Training accuracy: %f / Test accuracy : %f\" % (i, accs_train[i], accs_test[i]))\n",
    "\n",
    "print(\"\\nAverage test accuracy: %f\" % np.mean(accs_test))\n",
    "print(\"Variance test accuracy: %f\" % np.var(accs_test))\n",
    "print(\"Min test accuracy: %f\" % np.min(accs_test))\n",
    "print(\"Max test accuracy: %f\" % np.max(accs_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import *\n",
    "from crossvalidation import *\n",
    "from implementations import *\n",
    "\n",
    "data1, data2, data3, y1, y2, y3 = split_models_and_process(tX, y)\n",
    "\n",
    "data3_aug = data3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ridge3_test():\n",
    "    k_fold = 4\n",
    "\n",
    "    # Model parameters\n",
    "    lamb = 0.001\n",
    "\n",
    "    accs_train = []\n",
    "    accs_test = []\n",
    "\n",
    "    k_indices = build_k_indices(y3, k_fold, seed)\n",
    "\n",
    "    for k in range(k_fold):\n",
    "        acc_train, acc_test = cross_validation(y3, data3_aug, k_indices, k, ridge_regression, lambda_=lamb)\n",
    "        accs_train.append(acc_train)\n",
    "        accs_test.append(acc_test)\n",
    "\n",
    "    return np.mean(accs_test), np.max(accs_test)\n",
    "\n",
    "def not_tested(i, j):\n",
    "    test = [(3, 11), (2, 6), (6, 29), (2, 2), (2, 31), (3, 6), (2, 29), (18, 29)]\n",
    "    return not((i, j) in test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-114-cd96a38d641d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnot_tested\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[0mdata3_aug\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata3\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdata3\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m             \u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mridge3_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmean\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mmax_mean\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m                 \u001b[0mmax_mean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-113-8b90144522d4>\u001b[0m in \u001b[0;36mridge3_test\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk_fold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0macc_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata3_aug\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk_indices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mridge_regression\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlamb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0maccs_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macc_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0maccs_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macc_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Thomas\\workspace\\PROJET_ML\\crossvalidation.py\u001b[0m in \u001b[0;36mcross_validation\u001b[1;34m(y, x, k_indices, k, regression_method, **args)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0mx_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk_train\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     \u001b[0mx_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk_test\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m     \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk_train\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk_test\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "i_max, i_mean, j_max, j_mean = 0, 0, 0, 0\n",
    "max_mean, max_maxi = 0, 0\n",
    "acc_mean, acc_max = 0, 0\n",
    "for i in range(len(data3[0])):\n",
    "    for j in range(len(data3[0])):\n",
    "        if (not_tested(i, j)):\n",
    "            data3_aug = np.append(data3, np.array([(data3[:, i] * data3[:, j])]).T, axis=1)\n",
    "            mean, maxi = ridge3_test()\n",
    "            if mean > max_mean:\n",
    "                max_mean = mean\n",
    "                i_mean = i\n",
    "                j_mean = j\n",
    "            if maxi > max_maxi:\n",
    "                max_maxi = maxi\n",
    "                i_max = i\n",
    "                j_max = j\n",
    "            \n",
    "print(\"i_max: %d, j_max: %d, i_mean: %d, j_mean: %d\" % (i_max, j_max, i_mean, j_mean))\n",
    "print(\"new_mean: %f, new_max: %f\" % (max_mean, max_maxi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation results:\n",
    "\n",
    "columns 3 and 11 are the most correlated\n",
    "Then 2 and 6\n",
    "then 6 and 29\n",
    "then 2 and 2\n",
    "then (3 and 6) for the mean, and max accuracy increases most with (2, 31)\n",
    "then (18 and 29) for the mean, and max accuracy increases most with (2, 29)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Processing the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1, y_pred2, y_pred3 = predict_labels(w1, test1), predict_labels(w2, test2), predict_labels(w3, test3)\n",
    "y_pred = np.concatenate([y_pred1, y_pred2, y_pred3])\n",
    "ids_pred = np.concatenate([id1, id2, id3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
